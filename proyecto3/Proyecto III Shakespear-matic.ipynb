{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto II: Shakespear-Matic\n",
    "\n",
    "Debido a la falta de producción literaria de calidad (subjetivamente medida por el profesor Alexander), el profesor  Alexander ha decidio explorar la generación automatica de texto, para ver si de esa forma se puede lograr mejores obras contemporaneas. Debido a que los estudiantes del curso de NLP (Natural Language Processing) ya son expertos en la generación automatica de texto, el profesor ha decidio generar el siguiente reto para evaluar sus conocimientos y la calidad de estas herramientas  en la producción literaria.\n",
    "\n",
    "Para esta tarea el profesor quiere que los estudiantes entrenen diferentes sistemas para la generación de tres estilos literarios diferentes, ente los estilos que se desean observar los estudiantes pueden escoger entre: Novelas clásicas, cuentos de niños, poesia, letras de canciones (por favor NO regueton), obras de realismo mágico, entre otras.\n",
    "\n",
    "Para el desarrollo de esta tarea el profesor Alexander pide que se diseñen sistemas de generación automatica basada en palabras, para lo cual deben implementar en el pipeline:\n",
    "\n",
    "1. Adquisición de datos.\n",
    "2. Generación de vectors de palabras usando word2vec.\n",
    "3. Entrenamiento de los sistemas para los estilos literarios escogidos.\n",
    "4. Predicción del texto:\n",
    "    * Si la codificación se hizo con onehot encoding para la salida, el sistema produce de salida la siguiente palabra a generar.\n",
    "    * Si la codificación de salida se hizo con word2vec se debe implementar una busqueda de la palbra más cercana a la codificación generada por la salida de la red.\n",
    "      \n",
    "Tengan en cuenta que la relación entre la longitud del corpus y las palabras del vocabulario debe ser adecuada, para poder tener buenos resultados. El texto generado debe tener tambien en cuenta la puntuación.\n",
    "\n",
    "AL finalizar el proyecto, el profesor Alexander quiere que los estudiantes contesten las siguientes preguntas:\n",
    "\n",
    "1. ¿Qué pueden observar de los resusltados de los sistemas de generacion automatica para los tres estilos literarios diferentes? ¿Porqué considera que los resultados son de está forma?\n",
    "\n",
    "2. ¿Qué tamaño de N escogierón para la codificación de las palabras en vectores? ¿?Qué sucede si escogen un valor diferente de N?\n",
    "\n",
    "3. ¿Qué sucede si se cambia el número de palbras anteriores utilizados para predecir la palabra siguiiente en el modelo?\n",
    "\n",
    "4. ¿Qué ventajas y desventajas tienen las diferentes formas de codificar la salida - one hot encoding y word2vec?\n",
    "\n",
    "5. ¿Qué forma de codificación de la salida escogierón al final? ¿Porqué?\n",
    "\n",
    "6. ¿Qué pueden concluir del proyecto? ¿Cómo se pueden mejorar los resultados?\n",
    "\n",
    "Por favor al desarrollar el proyecto comentar cada bloque de codigo con un analisis de lo que esperan lograr y un análisis de los resultados preliminares. El proyecto se debe entregar a más tardar el **Domingo 2 de Mayo del 2021 a las 11:59 p.m. hora Bogotá**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer y procesar el archivo en texto plano.\n",
    "\n",
    "def get_file_data(fname, stop_word_removal='no'):\n",
    "    file_contents = []\n",
    "    with open(fname,encoding=\"utf-8\") as f:\n",
    "        file_contents = f.read()\n",
    "    text = []\n",
    "    for val in file_contents.split('.'):\n",
    "        val = re.sub(r'[,¡!¿?;-]+','.',val)\n",
    "        val = re.sub(r'á','a',val)\n",
    "        val = re.sub(r'é','e',val)\n",
    "        val = re.sub(r'í','i',val)\n",
    "        val = re.sub(r'ó','o',val)\n",
    "        val = re.sub(r'ú','u',val)\n",
    "        val = re.sub(r'Á','A',val)\n",
    "        val = re.sub(r'É','E',val)\n",
    "        val = re.sub(r'Í','I',val)\n",
    "        val = re.sub(r'Ó','O',val)\n",
    "        val = re.sub(r'Ú','U',val)\n",
    "        val = re.sub(r'ñ','n',val)\n",
    "        val = re.sub(r'Ñ','N',val)\n",
    "        sent = re.findall(\"[A-Za-z]+\", val)\n",
    "        line = ''\n",
    "        for words in sent:\n",
    "            \n",
    "            if stop_word_removal == 'yes': \n",
    "                if len(words) > 1 and words not in stop_words:\n",
    "                    line = line + ' ' + words\n",
    "            else:\n",
    "                if len(words) > 1 :\n",
    "                    line = line + ' ' + words\n",
    "        text.append(line)\n",
    "    return text\n",
    "\n",
    "# Función para obtener un Vocabulario en función del texto procesado\n",
    "\n",
    "def generate_dictinoary_data(text):\n",
    "    word_to_index= dict()\n",
    "    index_to_word = dict()\n",
    "    corpus = []\n",
    "    count = 0\n",
    "    vocab_size = 0\n",
    "    \n",
    "    for row in text:\n",
    "        for word in row.split():\n",
    "            word = word.lower()\n",
    "            corpus.append(word)\n",
    "            if word_to_index.get(word) == None:\n",
    "                word_to_index.update ( {word : count})\n",
    "                index_to_word.update ( {count : word })\n",
    "                count  += 1\n",
    "    vocab_size = len(word_to_index)\n",
    "    length_of_corpus = len(corpus)\n",
    "    \n",
    "    return word_to_index,index_to_word,corpus,vocab_size,length_of_corpus\n",
    "\n",
    "# Función para generar representaciones one hot de los vectores target y del corpus\n",
    "\n",
    "def get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index):\n",
    "    \n",
    "    #Create an array of size = vocab_size filled with zeros\n",
    "    trgt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    #Get the index of the target_word according to the dictionary word_to_index. \n",
    "    index_of_word_dictionary = word_to_index.get(target_word) \n",
    "    \n",
    "    #Set the index to 1\n",
    "    trgt_word_vector[index_of_word_dictionary] = 1\n",
    "    \n",
    "    #Repeat same steps for context_words but in a loop\n",
    "    ctxt_word_vector = np.zeros(vocab_size)\n",
    "    \n",
    "    \n",
    "    for word in context_words:\n",
    "        index_of_word_dictionary = word_to_index.get(word) \n",
    "        ctxt_word_vector[index_of_word_dictionary] = 1\n",
    "        \n",
    "    return trgt_word_vector,ctxt_word_vector\n",
    "\n",
    "# Función para generar los datos de entrenamiento para la red neuronal que representa el modelo word2vec\n",
    "\n",
    "def generate_training_data(corpus,window_size,vocab_size,word_to_index,length_of_corpus,sample=None):\n",
    "\n",
    "    training_data =  []\n",
    "    training_sample_words =  []\n",
    "    for i,word in enumerate(corpus):\n",
    "\n",
    "        index_target_word = i\n",
    "        target_word = word\n",
    "        context_words = []\n",
    "\n",
    "        #when target word is the first word\n",
    "        if i == 0:  \n",
    "\n",
    "            # trgt_word_index:(0), ctxt_word_index:(1,2)\n",
    "            context_words = [corpus[x] for x in range(i + 1 , window_size + 1)] \n",
    "\n",
    "\n",
    "        #when target word is the last word\n",
    "        elif i == len(corpus)-1:\n",
    "\n",
    "            # trgt_word_index:(9), ctxt_word_index:(8,7), length_of_corpus = 10\n",
    "            context_words = [corpus[x] for x in range(length_of_corpus - 2 ,length_of_corpus -2 - window_size  , -1 )]\n",
    "\n",
    "        #When target word is the middle word\n",
    "        else:\n",
    "\n",
    "            #Before the middle target word\n",
    "            before_target_word_index = index_target_word - 1\n",
    "            for x in range(before_target_word_index, before_target_word_index - window_size , -1):\n",
    "                if x >=0:\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "            #After the middle target word\n",
    "            after_target_word_index = index_target_word + 1\n",
    "            for x in range(after_target_word_index, after_target_word_index + window_size):\n",
    "                if x < len(corpus):\n",
    "                    context_words.extend([corpus[x]])\n",
    "\n",
    "\n",
    "        trgt_word_vector,ctxt_word_vector = get_one_hot_vectors(target_word,context_words,vocab_size,word_to_index)\n",
    "        training_data.append([trgt_word_vector,ctxt_word_vector])   \n",
    "        \n",
    "        if sample is not None:\n",
    "            training_sample_words.append([target_word,context_words])   \n",
    "        \n",
    "    return training_data,training_sample_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'cuento.txt' #Nombre del archivo\n",
    "C = 2 # Número de palabras de contexto a la derecha y a la izquierda\n",
    "text = get_file_data(fname, stop_word_removal='no')\n",
    "word_to_index,index_to_word,corpus,vocab_size,length_of_corpus = generate_dictinoary_data(text)\n",
    "training_data,training_sample_words = generate_training_data(corpus,C,vocab_size,word_to_index,length_of_corpus,sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de entrada y de salida\n",
    "X = np.array([x[1] for x in training_data])\n",
    "Y = np.array([y[0] for y in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo red neuronal\n",
    "model = Sequential()  \n",
    "model.add(Dense(100,input_shape=(vocab_size,), activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='CategoricalCrossentropy', optimizer='rmsprop', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "387/387 [==============================] - 4s 10ms/step - loss: 2.4177 - accuracy: 0.6263\n",
      "Epoch 2/100\n",
      "387/387 [==============================] - 4s 10ms/step - loss: 2.3757 - accuracy: 0.6326\n",
      "Epoch 3/100\n",
      "387/387 [==============================] - 4s 11ms/step - loss: 2.3337 - accuracy: 0.6376\n",
      "Epoch 4/100\n",
      "387/387 [==============================] - 4s 11ms/step - loss: 2.2903 - accuracy: 0.6415\n",
      "Epoch 5/100\n",
      "387/387 [==============================] - 4s 11ms/step - loss: 2.2489 - accuracy: 0.6448\n",
      "Epoch 6/100\n",
      "387/387 [==============================] - 4s 11ms/step - loss: 2.2082 - accuracy: 0.6511\n",
      "Epoch 7/100\n",
      "387/387 [==============================] - 4s 10ms/step - loss: 2.1667 - accuracy: 0.6560\n",
      "Epoch 8/100\n",
      "387/387 [==============================] - 4s 10ms/step - loss: 2.1262 - accuracy: 0.6602\n",
      "Epoch 9/100\n",
      "387/387 [==============================] - 5s 12ms/step - loss: 2.0868 - accuracy: 0.6653\n",
      "Epoch 10/100\n",
      "387/387 [==============================] - 4s 9ms/step - loss: 2.0473 - accuracy: 0.6703\n",
      "Epoch 11/100\n",
      "387/387 [==============================] - 3s 9ms/step - loss: 2.0090 - accuracy: 0.6751\n",
      "Epoch 12/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 1.9702 - accuracy: 0.6809\n",
      "Epoch 13/100\n",
      "387/387 [==============================] - 4s 11ms/step - loss: 1.9323 - accuracy: 0.6859 0s - l\n",
      "Epoch 14/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 1.8941 - accuracy: 0.6908\n",
      "Epoch 15/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 1.8582 - accuracy: 0.6960\n",
      "Epoch 16/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.8208 - accuracy: 0.7011\n",
      "Epoch 17/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.7851 - accuracy: 0.7082\n",
      "Epoch 18/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.7499 - accuracy: 0.7138\n",
      "Epoch 19/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.7132 - accuracy: 0.7179\n",
      "Epoch 20/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.6797 - accuracy: 0.7244\n",
      "Epoch 21/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.6455 - accuracy: 0.7294\n",
      "Epoch 22/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.6120 - accuracy: 0.7332\n",
      "Epoch 23/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.5800 - accuracy: 0.7377\n",
      "Epoch 24/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.5463 - accuracy: 0.7428\n",
      "Epoch 25/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.5149 - accuracy: 0.7466\n",
      "Epoch 26/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.4828 - accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.4521 - accuracy: 0.7551\n",
      "Epoch 28/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.4207 - accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.3901 - accuracy: 0.7631\n",
      "Epoch 30/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.3603 - accuracy: 0.7665\n",
      "Epoch 31/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.3294 - accuracy: 0.7691\n",
      "Epoch 32/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.3001 - accuracy: 0.7720\n",
      "Epoch 33/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.2702 - accuracy: 0.7758\n",
      "Epoch 34/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.2404 - accuracy: 0.7793\n",
      "Epoch 35/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.2113 - accuracy: 0.7823\n",
      "Epoch 36/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.1818 - accuracy: 0.7876\n",
      "Epoch 37/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.1533 - accuracy: 0.7905\n",
      "Epoch 38/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.1250 - accuracy: 0.7935\n",
      "Epoch 39/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.0964 - accuracy: 0.7976\n",
      "Epoch 40/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.0676 - accuracy: 0.8013\n",
      "Epoch 41/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.0401 - accuracy: 0.8050\n",
      "Epoch 42/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 1.0122 - accuracy: 0.8089\n",
      "Epoch 43/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.9844 - accuracy: 0.8126\n",
      "Epoch 44/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.9576 - accuracy: 0.8170\n",
      "Epoch 45/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.9304 - accuracy: 0.8204\n",
      "Epoch 46/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.9035 - accuracy: 0.8256\n",
      "Epoch 47/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.8783 - accuracy: 0.8302\n",
      "Epoch 48/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.8512 - accuracy: 0.8339\n",
      "Epoch 49/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.8260 - accuracy: 0.8393\n",
      "Epoch 50/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 0.8021 - accuracy: 0.8425\n",
      "Epoch 51/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.7773 - accuracy: 0.8464\n",
      "Epoch 52/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.7539 - accuracy: 0.8508\n",
      "Epoch 53/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.7310 - accuracy: 0.8552\n",
      "Epoch 54/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.7089 - accuracy: 0.8588\n",
      "Epoch 55/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.6868 - accuracy: 0.8637\n",
      "Epoch 56/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.6657 - accuracy: 0.8683\n",
      "Epoch 57/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.6448 - accuracy: 0.8727\n",
      "Epoch 58/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.6252 - accuracy: 0.8768\n",
      "Epoch 59/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.6056 - accuracy: 0.8800\n",
      "Epoch 60/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5867 - accuracy: 0.8836\n",
      "Epoch 61/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5691 - accuracy: 0.8868\n",
      "Epoch 62/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5513 - accuracy: 0.8893\n",
      "Epoch 63/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5341 - accuracy: 0.8924\n",
      "Epoch 64/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5178 - accuracy: 0.8974\n",
      "Epoch 65/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.5014 - accuracy: 0.8998\n",
      "Epoch 66/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4857 - accuracy: 0.9035\n",
      "Epoch 67/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4704 - accuracy: 0.9076\n",
      "Epoch 68/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4553 - accuracy: 0.9105\n",
      "Epoch 69/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4416 - accuracy: 0.9126\n",
      "Epoch 70/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 0.4277 - accuracy: 0.9161\n",
      "Epoch 71/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4133 - accuracy: 0.9186\n",
      "Epoch 72/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.4012 - accuracy: 0.9215\n",
      "Epoch 73/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3883 - accuracy: 0.9247\n",
      "Epoch 74/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3753 - accuracy: 0.9269\n",
      "Epoch 75/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 0.3645 - accuracy: 0.9288\n",
      "Epoch 76/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3520 - accuracy: 0.9320\n",
      "Epoch 77/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3409 - accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3309 - accuracy: 0.9354\n",
      "Epoch 79/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3206 - accuracy: 0.9378\n",
      "Epoch 80/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.3112 - accuracy: 0.9403\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 2s 6ms/step - loss: 0.3005 - accuracy: 0.9420\n",
      "Epoch 82/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2925 - accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2843 - accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2748 - accuracy: 0.9464\n",
      "Epoch 85/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2663 - accuracy: 0.9475\n",
      "Epoch 86/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2586 - accuracy: 0.9492\n",
      "Epoch 87/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2506 - accuracy: 0.9503\n",
      "Epoch 88/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2432 - accuracy: 0.9520\n",
      "Epoch 89/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2367 - accuracy: 0.9530\n",
      "Epoch 90/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2294 - accuracy: 0.9549: 0s - loss: 0.2290 - \n",
      "Epoch 91/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2227 - accuracy: 0.9553\n",
      "Epoch 92/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2156 - accuracy: 0.9563\n",
      "Epoch 93/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.2099 - accuracy: 0.9580\n",
      "Epoch 94/100\n",
      "387/387 [==============================] - 3s 8ms/step - loss: 0.2040 - accuracy: 0.9597\n",
      "Epoch 95/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1976 - accuracy: 0.9616\n",
      "Epoch 96/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1922 - accuracy: 0.9620\n",
      "Epoch 97/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1865 - accuracy: 0.9637\n",
      "Epoch 98/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1813 - accuracy: 0.9654\n",
      "Epoch 99/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1763 - accuracy: 0.9657\n",
      "Epoch 100/100\n",
      "387/387 [==============================] - 3s 7ms/step - loss: 0.1709 - accuracy: 0.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17affd43280>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenando\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo representaciones de los vectores con las matrices de pesos\n",
    "W1 = model.get_weights()[0]\n",
    "W2 = model.get_weights()[2]\n",
    "W_c = 0.5*(W2.T+W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(D,v):\n",
    "    k = np.where(D==v)[0].tolist()\n",
    "    i = max(set(k),key=k.count)\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'novela.txt' #Nombre del archivo\n",
    "C = 2 # Número de palabras de contexto a la derecha y a la izquierda\n",
    "text = get_file_data(fname, stop_word_removal='no')\n",
    "word_to_index,index_to_word,corpus,vocab_size,length_of_corpus = generate_dictinoary_data(text)\n",
    "training_data,training_sample_words = generate_training_data(corpus,C,vocab_size,word_to_index,length_of_corpus,sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x[1] for x in training_data])\n",
    "Y = np.array([y[0] for y in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo red neuronal\n",
    "model = Sequential()  \n",
    "model.add(Dense(100,input_shape=(vocab_size,), activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='CategoricalCrossentropy', optimizer='rmsprop', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "614/614 [==============================] - 17s 27ms/step - loss: 6.5982 - accuracy: 0.0569\n",
      "Epoch 2/100\n",
      "614/614 [==============================] - 13s 21ms/step - loss: 6.1162 - accuracy: 0.0773\n",
      "Epoch 3/100\n",
      "614/614 [==============================] - 12s 20ms/step - loss: 5.9366 - accuracy: 0.0862\n",
      "Epoch 4/100\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 5.8088 - accuracy: 0.0965\n",
      "Epoch 5/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 5.7089 - accuracy: 0.1060\n",
      "Epoch 6/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 5.6294 - accuracy: 0.1115\n",
      "Epoch 7/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.5612 - accuracy: 0.1182\n",
      "Epoch 8/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.5070 - accuracy: 0.1242\n",
      "Epoch 9/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.4622 - accuracy: 0.1326\n",
      "Epoch 10/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.4246 - accuracy: 0.1398\n",
      "Epoch 11/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.3923 - accuracy: 0.1523\n",
      "Epoch 12/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.3668 - accuracy: 0.1635\n",
      "Epoch 13/100\n",
      "614/614 [==============================] - 8s 14ms/step - loss: 5.3441 - accuracy: 0.1728\n",
      "Epoch 14/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.3239 - accuracy: 0.1852\n",
      "Epoch 15/100\n",
      "614/614 [==============================] - 8s 14ms/step - loss: 5.3040 - accuracy: 0.1950\n",
      "Epoch 16/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.2869 - accuracy: 0.2073\n",
      "Epoch 17/100\n",
      "614/614 [==============================] - 8s 14ms/step - loss: 5.2687 - accuracy: 0.2201\n",
      "Epoch 18/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.2533 - accuracy: 0.2291\n",
      "Epoch 19/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.2356 - accuracy: 0.2404\n",
      "Epoch 20/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.2186 - accuracy: 0.2504\n",
      "Epoch 21/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.2016 - accuracy: 0.2604\n",
      "Epoch 22/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.1829 - accuracy: 0.2711\n",
      "Epoch 23/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.1632 - accuracy: 0.2794\n",
      "Epoch 24/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.1443 - accuracy: 0.2893\n",
      "Epoch 25/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.1253 - accuracy: 0.2974\n",
      "Epoch 26/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.1037 - accuracy: 0.3040\n",
      "Epoch 27/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.0832 - accuracy: 0.3108\n",
      "Epoch 28/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 5.0596 - accuracy: 0.3187\n",
      "Epoch 29/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.0363 - accuracy: 0.3249\n",
      "Epoch 30/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 5.0119 - accuracy: 0.3313\n",
      "Epoch 31/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.9891 - accuracy: 0.3358\n",
      "Epoch 32/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 4.9628 - accuracy: 0.3425\n",
      "Epoch 33/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 4.9380 - accuracy: 0.3480\n",
      "Epoch 34/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 4.9128 - accuracy: 0.3546\n",
      "Epoch 35/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.8859 - accuracy: 0.3602\n",
      "Epoch 36/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.8581 - accuracy: 0.3649\n",
      "Epoch 37/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.8318 - accuracy: 0.3685\n",
      "Epoch 38/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.8046 - accuracy: 0.3738\n",
      "Epoch 39/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.7764 - accuracy: 0.3784\n",
      "Epoch 40/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.7487 - accuracy: 0.3831\n",
      "Epoch 41/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.7214 - accuracy: 0.3875\n",
      "Epoch 42/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.6940 - accuracy: 0.3920\n",
      "Epoch 43/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.6673 - accuracy: 0.3967\n",
      "Epoch 44/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.6419 - accuracy: 0.3999\n",
      "Epoch 45/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.6149 - accuracy: 0.4042\n",
      "Epoch 46/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.5898 - accuracy: 0.4091\n",
      "Epoch 47/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.5630 - accuracy: 0.4129\n",
      "Epoch 48/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.5384 - accuracy: 0.4174\n",
      "Epoch 49/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.5137 - accuracy: 0.4202\n",
      "Epoch 50/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.4890 - accuracy: 0.4246\n",
      "Epoch 51/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.4656 - accuracy: 0.4261\n",
      "Epoch 52/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.4408 - accuracy: 0.4294\n",
      "Epoch 53/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.4168 - accuracy: 0.4322\n",
      "Epoch 54/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.3930 - accuracy: 0.4359\n",
      "Epoch 55/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.3685 - accuracy: 0.4386\n",
      "Epoch 56/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.3446 - accuracy: 0.4408\n",
      "Epoch 57/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.3213 - accuracy: 0.4452\n",
      "Epoch 58/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.3000 - accuracy: 0.4481\n",
      "Epoch 59/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.2757 - accuracy: 0.4504\n",
      "Epoch 60/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.2526 - accuracy: 0.4535\n",
      "Epoch 61/100\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 4.2285 - accuracy: 0.4556\n",
      "Epoch 62/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.2060 - accuracy: 0.4580\n",
      "Epoch 63/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.1837 - accuracy: 0.4610\n",
      "Epoch 64/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.1627 - accuracy: 0.4638\n",
      "Epoch 65/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.1386 - accuracy: 0.4660\n",
      "Epoch 66/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.1158 - accuracy: 0.4668\n",
      "Epoch 67/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.0947 - accuracy: 0.4711\n",
      "Epoch 68/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.0721 - accuracy: 0.4736\n",
      "Epoch 69/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.0510 - accuracy: 0.4750\n",
      "Epoch 70/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 4.0289 - accuracy: 0.4769\n",
      "Epoch 71/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 4.0067 - accuracy: 0.4787\n",
      "Epoch 72/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.9871 - accuracy: 0.4803\n",
      "Epoch 73/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.9664 - accuracy: 0.4838\n",
      "Epoch 74/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.9428 - accuracy: 0.4852\n",
      "Epoch 75/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.9223 - accuracy: 0.4874\n",
      "Epoch 76/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.9022 - accuracy: 0.4902\n",
      "Epoch 77/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.8822 - accuracy: 0.4919\n",
      "Epoch 78/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.8621 - accuracy: 0.4931\n",
      "Epoch 79/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.8416 - accuracy: 0.4958\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 9s 14ms/step - loss: 3.8218 - accuracy: 0.4968\n",
      "Epoch 81/100\n",
      "614/614 [==============================] - 8s 13ms/step - loss: 3.8027 - accuracy: 0.4992\n",
      "Epoch 82/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.7820 - accuracy: 0.5010\n",
      "Epoch 83/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.7622 - accuracy: 0.5032\n",
      "Epoch 84/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.7430 - accuracy: 0.5044\n",
      "Epoch 85/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.7208 - accuracy: 0.5063\n",
      "Epoch 86/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.7013 - accuracy: 0.5081\n",
      "Epoch 87/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.6813 - accuracy: 0.5098\n",
      "Epoch 88/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.6623 - accuracy: 0.5116\n",
      "Epoch 89/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.6440 - accuracy: 0.5154\n",
      "Epoch 90/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.6239 - accuracy: 0.5163\n",
      "Epoch 91/100\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 3.6048 - accuracy: 0.5169\n",
      "Epoch 92/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.5860 - accuracy: 0.5191\n",
      "Epoch 93/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.5659 - accuracy: 0.5217\n",
      "Epoch 94/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.5459 - accuracy: 0.5232\n",
      "Epoch 95/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.5272 - accuracy: 0.5253\n",
      "Epoch 96/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.5073 - accuracy: 0.5271\n",
      "Epoch 97/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.4878 - accuracy: 0.5287\n",
      "Epoch 98/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.4685 - accuracy: 0.5311\n",
      "Epoch 99/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.4492 - accuracy: 0.5328\n",
      "Epoch 100/100\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 3.4303 - accuracy: 0.5352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17aab46a940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenando\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
